{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from scipy.stats import dirichlet, multinomial\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jt -t gruvboxd\n",
    "#!jt -t gruvboxd -T -N\n",
    "stops = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>STORY</th>\n",
       "      <th>HOSTNAME</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>http://www.latimes.com/business/money/la-fi-mo...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.latimes.com</td>\n",
       "      <td>1394470370698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>http://www.livemint.com/Politics/H2EvwJSK2VE6O...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.livemint.com</td>\n",
       "      <td>1394470371207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/us-open-stocks...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/fed-risks-fall...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>http://www.moneynews.com/Economy/federal-reser...</td>\n",
       "      <td>Moneynews</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.moneynews.com</td>\n",
       "      <td>1394470372027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1  Fed official says weak data caused by weather,...   \n",
       "1   2  Fed's Charles Plosser sees high bar for change...   \n",
       "2   3  US open: Stocks fall after Fed official hints ...   \n",
       "3   4  Fed risks falling 'behind the curve', Charles ...   \n",
       "4   5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n",
       "\n",
       "                                                 URL          PUBLISHER  \\\n",
       "0  http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n",
       "1  http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n",
       "2  http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \n",
       "3  http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \n",
       "4  http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n",
       "\n",
       "  CATEGORY                          STORY             HOSTNAME      TIMESTAMP  \n",
       "0        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.latimes.com  1394470370698  \n",
       "1        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM     www.livemint.com  1394470371207  \n",
       "2        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371550  \n",
       "3        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371793  \n",
       "4        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM    www.moneynews.com  1394470372027  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv('uci-news-aggregator.csv')\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(token: str):\n",
    "    '''\n",
    "    Function that formats and strips each word of junk characters and removes stopwords\n",
    "    '''\n",
    "    return re.sub(r'[^a-zA-Z\\s-]','',token.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Fed official says weak data caused by weather,...\n",
       "1    Fed's Charles Plosser sees high bar for change...\n",
       "2    US open: Stocks fall after Fed official hints ...\n",
       "3    Fed risks falling 'behind the curve', Charles ...\n",
       "4    Fed's Plosser: Nasty Weather Has Curbed Job Gr...\n",
       "5    Plosser: Fed May Have to Accelerate Tapering Pace\n",
       "6            Fed's Plosser: Taper pace may be too slow\n",
       "7    Fed's Plosser expects US unemployment to fall ...\n",
       "8    US jobs growth last month hit by weather:Fed P...\n",
       "9    ECB unlikely to end sterilisation of SMP purch...\n",
       "Name: TITLE, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data.iloc[:10000,1].astype(str)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fed official says weak data caused weather slow taper',\n",
       "       'feds charles plosser sees high bar change pace tapering',\n",
       "       'us open stocks fall fed official hints accelerated tapering',\n",
       "       'fed risks falling behind curve charles plosser says',\n",
       "       'feds plosser nasty weather curbed job growth',\n",
       "       'plosser fed may accelerate tapering pace',\n",
       "       'feds plosser taper pace may slow',\n",
       "       'feds plosser expects us unemployment fall  end ',\n",
       "       'us jobs growth last month hit weatherfed president charles plosser',\n",
       "       'ecb unlikely end sterilisation smp purchases - traders'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_documents = df_data.iloc[:20000,1].astype(str).apply(lambda x: preprocess(x)).to_numpy()\n",
    "stops = set(stopwords.words('english'))\n",
    "for r in range(len(raw_documents)):\n",
    "        words = raw_documents[r].split(' ')\n",
    "        words = [w for w in words if w not in stops]\n",
    "        raw_documents[r] = ' '.join(words)\n",
    "raw_documents[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get first 10K documents\n",
    "#raw_documents = raw_documents[:10000]\n",
    "#raw_documents\n",
    "raw_documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['diplomacy',\n",
       "  'replacing',\n",
       "  'sizing',\n",
       "  'refer',\n",
       "  'mp',\n",
       "  'empowerment',\n",
       "  'wake',\n",
       "  'fidelity',\n",
       "  'brake',\n",
       "  'waive'],\n",
       " 12941)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [d.split() for d in raw_documents]\n",
    "vocab = list(set(' '.join(raw_documents).split()))\n",
    "vocab[:10],len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,\n",
       " [[5241, 2267, 8862, 5964, 5615, 1895, 3357, 3260, 6032],\n",
       "  [4283, 9709, 3700, 6959, 8967, 1120, 7120, 2123, 3104],\n",
       "  [2732, 10914, 6233, 8244, 5241, 2267, 3308, 4404, 3104],\n",
       "  [5241, 9930, 5094, 9278, 3788, 9709, 3700, 8862],\n",
       "  [4283, 3700, 7740, 3357, 4446, 1533, 5313]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create word ids\n",
    "mapped_docs = []\n",
    "longest_doc_length = 0\n",
    "for doc in docs:\n",
    "    new_doc = []\n",
    "    vectorized_doc = doc\n",
    "    doc_len = len(doc)\n",
    "    for i in range(doc_len):\n",
    "        vectorized_doc[i] = vocab.index(doc[i])\n",
    "    longest_doc_length = max(longest_doc_length, len(vectorized_doc))\n",
    "    mapped_docs.append(vectorized_doc)\n",
    "len(mapped_docs), mapped_docs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longest_doc_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of topics\n",
    "K = 50\n",
    "num_iterations = 50\n",
    "#topic-word matrix\n",
    "tw_matrix = np.zeros((K,len(vocab)))\n",
    "\n",
    "#topic assignment history\n",
    "\n",
    "assignments = np.zeros((len(mapped_docs), longest_doc_length, num_iterations+1 ), dtype=int)\n",
    "\n",
    "\n",
    "#document-topic matrix\n",
    "dt_matrix = np.zeros((len(docs),K))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly intitialize\n",
    "for d in range(len(docs)):\n",
    "    for w in range(len(mapped_docs[d])):\n",
    "        ti = np.random.randint(0,K)\n",
    "        assignments[d,w,0] = ti\n",
    "        wi = int(mapped_docs[d][w])\n",
    "        tw_matrix[ti, wi] += 1\n",
    "        dt_matrix[d,ti] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(tw_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(dt_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model paramters\n",
    "alpha = 1\n",
    "eta = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/50\n",
      "1/50\n",
      "2/50\n",
      "3/50\n",
      "4/50\n",
      "5/50\n",
      "6/50\n",
      "7/50\n",
      "8/50\n",
      "9/50\n",
      "10/50\n",
      "11/50\n",
      "12/50\n",
      "13/50\n",
      "14/50\n",
      "15/50\n",
      "16/50\n",
      "17/50\n",
      "18/50\n",
      "19/50\n",
      "20/50\n",
      "21/50\n",
      "22/50\n",
      "23/50\n",
      "24/50\n",
      "25/50\n",
      "26/50\n",
      "27/50\n",
      "28/50\n",
      "29/50\n",
      "30/50\n",
      "31/50\n",
      "32/50\n",
      "33/50\n",
      "34/50\n",
      "35/50\n",
      "36/50\n",
      "37/50\n",
      "38/50\n",
      "39/50\n",
      "40/50\n",
      "41/50\n",
      "42/50\n",
      "43/50\n",
      "44/50\n",
      "45/50\n",
      "46/50\n",
      "47/50\n",
      "48/50\n",
      "49/50\n"
     ]
    }
   ],
   "source": [
    "#calculating P(z_i|*)\n",
    "for iteration in range(num_iterations):    \n",
    "    print(f'{iteration}/{num_iterations}')\n",
    "    for d_i in range(len(mapped_docs)):\n",
    "        for w_i in range(len(mapped_docs[d_i])):\n",
    "            init_topic = int(assignments[d_i, w_i, iteration])\n",
    "            #print(init_topic == 0)\n",
    "            word_id = mapped_docs[d_i][w_i] \n",
    "            #z_-i term\n",
    "            dt_matrix[d_i, init_topic] -= 1\n",
    "            tw_matrix[init_topic, word_id] -= 1\n",
    "            #word topic means\n",
    "            wt_means = (tw_matrix[:, word_id] + eta) / (tw_matrix.sum(axis=1) + len(vocab)*eta)\n",
    "            dt_means = (dt_matrix[d_i,:]+alpha) / (dt_matrix[d_i,:].sum() + K*alpha )\n",
    "            probs = wt_means*dt_means\n",
    "            #Normalize, necessary due to rounding errors\n",
    "            probs = probs/probs.sum()\n",
    "\n",
    "            #Multinomial draws\n",
    "            new_topic = np.argmax(np.random.multinomial(1,probs))\n",
    "            dt_matrix[d_i, new_topic] += 1\n",
    "            tw_matrix[new_topic, word_id] += 1\n",
    "            #update topic assignment list\n",
    "            assignments[d_i,w_i, iteration+1] = new_topic\n",
    "            #if new_topic != init_topic:\n",
    "            #    print(f'{init_topic} -> {new_topic}')\n",
    "\n",
    "\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>12931</th>\n",
       "      <th>12932</th>\n",
       "      <th>12933</th>\n",
       "      <th>12934</th>\n",
       "      <th>12935</th>\n",
       "      <th>12936</th>\n",
       "      <th>12937</th>\n",
       "      <th>12938</th>\n",
       "      <th>12939</th>\n",
       "      <th>12940</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 12941 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0    0.0    0.0    0.0    0.0    2.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "1    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "3    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0  ...   \n",
       "4    0.0    0.0    0.0    0.0    1.0    1.0    0.0    0.0    0.0    0.0  ...   \n",
       "\n",
       "   12931  12932  12933  12934  12935  12936  12937  12938  12939  12940  \n",
       "0    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
       "1    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3    0.0    0.0    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0  \n",
       "4    0.0    0.0    0.0    1.0    0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "\n",
       "[5 rows x 12941 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tw = pd.DataFrame(tw_matrix)\n",
    "df_dt = pd.DataFrame(dt_matrix)\n",
    "df_tw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_lists = []\n",
    "for k in range(K):\n",
    "    topic_k_words = df_tw.iloc[k, :].array\n",
    "    #Get top 10 words for topic k\n",
    "    top_words_ind = np.argpartition(topic_k_words, -10)[-10:]\n",
    "    top_words = [vocab[v] for v in top_words_ind]\n",
    "    word_lists.append(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic 0:billion, noah, new, finale, candy, china, bachelor, gold, mortgage, -',\n",
       " 'topic 1:gas, chiquita, ukraine, may, video, new, cancer, bieber, sxsw, chinese',\n",
       " 'topic 2:faces, million, snowden, test, bieber, rates, thrones, justin, true, gm',\n",
       " 'topic 3:starbucks, bank, selena, google, shows, gm, plane, thrones, sxsw, justin',\n",
       " 'topic 4:sxsw, gold, titanfall, bitcoin, stocks, snowden, true, gm, test, recall',\n",
       " 'topic 5:miley, chris, watch, new, first, google, xbox, -, video, season',\n",
       " 'topic 6:growth, last, one, weak, launch, new, bachelor, bieber, data, gm',\n",
       " 'topic 7:-, ipo, ban, jos, may, new, us, watch, company, ukraine',\n",
       " 'topic 8:ukraine, dunham, titanfall, growth, china, bank, season, lena, us, xbox',\n",
       " 'topic 9:day, live, -, new, china, bitcoin, bieber, trailer, may, us',\n",
       " 'topic 10:-, company, video, selena, sxsw, bieber, titanfall, justin, gomez, new',\n",
       " 'topic 11:cyrus, cosmos, back, sxsw, game, neil, makes, clooneys, -, china',\n",
       " 'topic 12:juan, bankruptcy, stacy, mortgage, update, bieber, google, us, files, titanfall',\n",
       " 'topic 13:dressing, high, us, new, says, bankruptcy, swift, airlines, titanfall, wearables',\n",
       " 'topic 14:bitcoin, crush, game, gas, alzheimers, bank, -, bachelor, stocks, missing',\n",
       " 'topic 15:rose, gm, ferrell, candy, finale, nikki, bachelor, galavis, juan, pablo',\n",
       " 'topic 16:marijuana, ukraine, juan, bank, dunham, public, new, flash, iphone, gomez',\n",
       " 'topic 17:trailer, money, files, titanfall, bachelor, xbox, one, launch, release, live',\n",
       " 'topic 18:-, app, gm, iphone, recall, bieber, billion, justin, china, us',\n",
       " 'topic 19:chinese, costume, recall, ban, sxsw, bachelor, new, gm, tv, lena',\n",
       " 'topic 20:sbarro, data, us, neil, market, ban, google, may, xbox, could',\n",
       " 'topic 21:big, help, new, oil, taylor, xbox, first, ios, us, ipo',\n",
       " 'topic 22:recall, investors, bank, gox, china, app, edward, one, gas, bieber',\n",
       " 'topic 23:game, snowden, recall, video, herbalife, cyrus, season, bachelor, china, one',\n",
       " 'topic 24:china, bieber, study, show, lena, says, -, ipo, us, sxsw',\n",
       " 'topic 25:stock, report, neil, young, titanfall, keibler, us, one, bank, chinas',\n",
       " 'topic 26:gm, stocks, gomez, sxsw, cosmos, live, titanfall, selena, dunham, us',\n",
       " 'topic 27:-, jos, game, justin, apple, dunham, bieber, colorado, season, first',\n",
       " 'topic 28:recall, deposition, bank, gox, company, gomez, million, justin, video, selena',\n",
       " 'topic 29:video, pablo, update, richards, us, sales, new, neil, justin, bieber',\n",
       " 'topic 30:lindsay, sxsw, gold, google, juan, player, video, titanfall, watch, china',\n",
       " 'topic 31:blood, one, justin, recall, says, sxsw, sales, herbalife, first, titanfall',\n",
       " 'topic 32:crush, update, test, blood, us, news, alzheimers, gomez, stocks, recall',\n",
       " 'topic 33:new, juan, first, one, justin, season, titanfall, taxes, bank, bieber',\n",
       " 'topic 34:film, shows, dance, titanfall, stocks, probe, us, china, justin, gm',\n",
       " 'topic 35:candy, sdk, george, probe, finale, new, us, gm, carney, says',\n",
       " 'topic 36:st, prices, one, stacy, snowden, bossy, drug, ukraine, new, gold',\n",
       " 'topic 37:fyffes, apple, says, us, live, recall, bieber, snowden, xbox, justin',\n",
       " 'topic 38:justin, stocks, gm, update, google, xbox, new, titanfall, lena, dunham',\n",
       " 'topic 39:use, miley, one, xbox, us, selena, lindsay, alzheimers, bachelor, -',\n",
       " 'topic 40:sxsw, gomez, finale, price, juan, gold, -, new, prices, bieber',\n",
       " 'topic 41:shares, launch, miley, video, makes, ukraine, richards, book, stocks, alzheimers',\n",
       " 'topic 42:bieber, true, justin, google, high, new, recap, dunham, says, selena',\n",
       " 'topic 43:genghis, dunham, cyrus, snowden, ftc, says, google, bieber, titanfall, gets',\n",
       " 'topic 44:colorado, marijuana, mt, sales, gold, one, us, season, new, recall',\n",
       " 'topic 45:detective, day, tv, one, us, juan, candy, bieber, lena, bossy',\n",
       " 'topic 46:xbox, google, selena, snowden, update, justin, bieber, us, keibler, says',\n",
       " 'topic 47:time, neil, stocks, new, video, data, ios, bieber, season, china',\n",
       " 'topic 48:bieber, george, -, gold, stacy, crush, march, bank, open, us',\n",
       " 'topic 49:taylor, get, keibler, test, lindsay, may, us, sales, price, data']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f'topic {i}:'+', '.join(word_lists[i]) for i in range(len(word_lists))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tw_matrix[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
